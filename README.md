# Lab-DeepLearning-MNIST-ViT-CNN

> Universit√© Abdelmalek Essa√¢di ‚Äì FST Tanger  
> Master MBD ‚Äì Deep Learning | Encadr√© par Pr. ELAACHAK LOTFI  
> Lab 2 ‚Äì Vision par ordinateur avec PyTorch (CNN, VGG, ViT)

---

## üéØ Objectif du TP

L‚Äôobjectif principal de cet atelier est de se familiariser avec la biblioth√®que **PyTorch** pour construire et entra√Æner diff√©rentes **architectures neuronales** appliqu√©es √† la vision par ordinateur. Nous avons explor√© des r√©seaux classiques comme **CNN**, des mod√®les pr√©-entra√Æn√©s (**VGG16, AlexNet**), ainsi que les **Transformers Visuels (ViT)**, sur le dataset **MNIST**.

---

## üìÇ Contenu

### Partie 1 ‚Äì Classification avec CNN

#### üß† √âtapes r√©alis√©es :
1. **Cr√©ation d‚Äôun mod√®le CNN personnalis√©** (convolutions, maxpool, fully connected).
2. **Utilisation de GPU (RTX 2060)** via `torch.device("cuda")`.
3. **Entra√Ænement et √©valuation du mod√®le CNN** (Accuracy, F1-score, Loss, Training Time).
4. **Fine-tuning de mod√®les pr√©-entra√Æn√©s** : `VGG16` et `AlexNet`.
5. **Comparaison des performances entre CNN, VGG16, AlexNet.**

#### üõ†Ô∏è Sp√©cificit√©s du CNN :
- Deux couches de convolution suivies de ReLU et MaxPool.
- Flatten ‚Üí Fully Connected ‚Üí Dropout ‚Üí Classification.
- Optimiseur : Adam, Loss : CrossEntropy.

---

### Partie 2 ‚Äì Vision Transformer (ViT)

#### üîç √âtapes suivies :
- Impl√©mentation d‚Äôun mod√®le **ViT from scratch**, inspir√© de l'article [An Image is Worth 16x16 Words](https://arxiv.org/abs/2010.11929).
- Utilisation de la m√©thode `PatchEmbedding`, position embeddings, et multi-head self-attention.
- Application sur le dataset **MNIST** apr√®s adaptation des dimensions (r√©solution et canaux).
- Entra√Ænement, √©valuation, puis **comparaison avec les mod√®les CNN & VGG**.

---

## üìä R√©sultats Comparatifs

| Mod√®le     | Accuracy (%) | F1-Score (%) | Temps d'entra√Ænement |
|------------|--------------|--------------|------------------------|
| CNN        | 98.00        | 97.90        | ~1 min                 |
| VGG16      | 99.20        | 99.15        | ~2 min                 |
| AlexNet    | 98.50        | 98.40        | ~1.5 min               |
| Vision Transformer (ViT) | 97.10        | 96.90        | ~3 min                 |

üìå *Ces chiffres sont obtenus apr√®s 3 √† 5 epochs d'entra√Ænement sur GPU (RTX 2060).*

---

## üß† Analyse & Interpr√©tation

- Le **mod√®le CNN personnalis√©** fonctionne tr√®s bien sur MNIST, montrant la puissance des convolutions sur des donn√©es simples.
- Le **VGG16** fine-tun√© d√©passe clairement les performances du CNN classique, montrant l‚Äôint√©r√™t du transfert d‚Äôapprentissage.
- Le **ViT**, bien que l√©g√®rement en dessous sur MNIST, reste comp√©titif m√™me sans CNN, prouvant sa g√©n√©ralisation.
- Les **temps d'entra√Ænement** montrent que les mod√®les Transformers sont plus gourmands que CNN/VGG pour ce dataset simple.

---

## üß™ Enseignements & Conclusion

‚úÖ Ce TP m‚Äôa permis de :
- Ma√Ætriser les concepts de **convolutions, pooling, FC layers, dropout, etc.**
- Comprendre le fonctionnement de **mod√®les pr√©-entra√Æn√©s** et comment les **adapter** √† un nouveau jeu de donn√©es.
- Impl√©menter un **mod√®le Transformer visuel (ViT)** √©tape par √©tape.
- Comparer plusieurs architectures de vision par ordinateur de mani√®re rigoureuse √† l‚Äôaide de m√©triques (Accuracy, F1, Time).

---

## üöÄ Outils & Environnement

- üî• **PyTorch** 2.x
- üìà **Sklearn** pour les m√©triques
- üéÆ **GPU** local : NVIDIA RTX 2060
- üß™ Jupyter Notebook
- üìö Dataset : [MNIST Digits Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)

---

## üìÅ Structure du Projet
üì¶ Atelier-DeepLearning-MNIST-ViT-CNN ‚î£ üìú Atelier2_final.ipynb ‚Üê Notebook complet (ex√©cutable) ‚î£ üìú README.md ‚Üê Ce fichier ‚îó üìÇ data/ ‚Üê T√©l√©charg√© automatiquement par PyTorch

---

## ‚úÖ √Ä faire pour la validation

- [x] Impl√©menter CNN et fine-tuning VGG16/AlexNet
- [x] Impl√©menter ViT from scratch
- [x] Comparer tous les mod√®les
- [x] Synth√®se finale dans le `README.md`
- [x] H√©berger le projet sur GitHub

---

## üîó R√©f√©rences

- [Tutorial ViT Medium](https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c)
- [Paper ViT original](https://arxiv.org/abs/2010.11929)
- [Dataset MNIST Kaggle](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)

---

> *Fait avec passion ‚ù§Ô∏è par [Mohamed BARBYCH]*

